{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO2C8CAv4lDi13Qp/04SpKl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zenith1618/LLM/blob/main/GPT4all.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GPT4all\n",
        "\n",
        "GPT4All is an ecosystem to train and deploy powerful and customized large language models that run locally on consumer grade CPUs.\n",
        "\n",
        "The goal is simple - be the best instruction tuned assistant-style language model that any person or enterprise can freely use, distribute and build on.\n",
        "\n",
        "A GPT4All model is a 3GB - 8GB file that you can download and plug into the GPT4All open-source ecosystem software. Nomic AI supports and maintains this software ecosystem to enforce quality and security alongside spearheading the effort to allow any person or enterprise to easily train and deploy their own on-edge large language models."
      ],
      "metadata": {
        "id": "MEOiekbrpP0A"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BifDodY9ozy2",
        "outputId": "4c2cf5ae-3a09-4f8b-ee70-997bdb4b18f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gpt4all\n",
            "  Downloading gpt4all-2.2.1.post1-py3-none-manylinux1_x86_64.whl (4.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from gpt4all) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gpt4all) (4.66.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->gpt4all) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->gpt4all) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->gpt4all) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->gpt4all) (2024.2.2)\n",
            "Installing collected packages: gpt4all\n",
            "Successfully installed gpt4all-2.2.1.post1\n"
          ]
        }
      ],
      "source": [
        "!pip install gpt4all"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint"
      ],
      "metadata": {
        "id": "hbqqeuH_raJS"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gpt4all import GPT4All\n",
        "model = GPT4All(\"gpt4all-falcon-newbpe-q4_0.gguf\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjMpGJvUo7aI",
        "outputId": "30bba197-053a-4bf2-8665-4645008a4498"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 45%|████▍     | 1.88G/4.21G [00:43<00:29, 77.9MiB/s]\n",
            "Download interrupted, resuming from byte position 1879048192\n",
            "100%|██████████| 4.21G/4.21G [02:24<00:00, 29.2MiB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   Very fast model with good quality\n",
        "*   Fastest responses\n",
        "*   Instruction based\n",
        "*   Trained by TII\n",
        "*   Finetuned by Nomic AI\n",
        "\n"
      ],
      "metadata": {
        "id": "wGKwp9FPqtJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output = model.generate(\"Write a python program to add two variables and print the sum\")"
      ],
      "metadata": {
        "id": "V0ius47ypEoT"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "UiwoczSkqll0",
        "outputId": "e00499ec-1644-406d-8a2b-c9776da2d938"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' of the two variables.\\nHere is an example Python program that adds two variables and prints their sum:\\n```\\ndef add_two_variables(x, y):\\n    return x + y\\n\\nsum = add_two_variables(5, 10)\\nprint(\"The sum of\", x, \"and\", y, \"is\", sum)\\n```\\nThis program defines a function called `add_two_variables` that takes two arguments, `x` and `y`, and returns their sum. The main part of the program then calls this function with the values 5 and 10, and prints the result to the console.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6heWNJnxqmZa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}