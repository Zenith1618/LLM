{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CwUiGQYYAa_"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtF4fbK1YBd6",
        "outputId": "8d06fdfd-46fc-4495-9a94-00db2964b72f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.2.10)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.36.1)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.22 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.22)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.2)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.93)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.5.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.7.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.22->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.22->langchain) (24.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.6)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.22->langchain) (3.0.0)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.10/dist-packages (0.2.9)\n",
            "Requirement already satisfied: langchain-core in /usr/local/lib/python3.10/dist-packages (0.2.22)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.0.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (3.9.5)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: langchain<0.3.0,>=0.2.9 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.2.10)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.1.93)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (1.25.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.31.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (24.1)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (2.8.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.21.3)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core) (3.0.0)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.9->langchain-community) (0.2.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-community) (3.10.6)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core) (2.20.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2024.7.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.0.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain openai\n",
        "!pip install langchain-community langchain-core"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ru4pZW5CYP7K"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import langchain\n",
        "import openai\n",
        "from pprint import pprint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9udQ5NjYGze"
      },
      "source": [
        "# Set-up Open-AI Key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_pi33d26YE80"
      },
      "outputs": [],
      "source": [
        "openai_key = \"#######\" #replace the key with your OpenAI Key\n",
        "os.environ['OPENAI_API_KEY'] = openai_key\n",
        "openai.api_key = os.environ['OPENAI_API_KEY']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "we9wkmkeY71u"
      },
      "source": [
        "# Model\n",
        "\n",
        "Chat models are a variation on language models. While chat models use language models under the hood, the interface they expose is a bit different. Rather than expose a \"text in, text out\" API, they expose an interface where \"chat messages\" are the inputs and outputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GRdjNtuEY0qn"
      },
      "outputs": [],
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.llms import OpenAI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKiw-mgYaSXV"
      },
      "source": [
        "## Chat Models\n",
        "\n",
        "Chat Models are the models that are usually backed by a language model, but their APIs are more structured. Specifically, these models take a list of Chat Messages as input, and return a Chat Message."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BYYR3kdWZH3F"
      },
      "outputs": [],
      "source": [
        "# To control the randomness and creativity of the generated, use temperature = 0.0 to 0.9\n",
        "chat = ChatOpenAI(temperature=0.2,max_tokens = 500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "jmqeYIIjafT3",
        "outputId": "5fed456b-89fe-4a1a-b1df-8b5329b37f14"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'gpt-3.5-turbo'"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chat.model_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rlppfNnhagzj",
        "outputId": "e6e6e0d6-666a-41c6-a8ff-000b913cee2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "500\n"
          ]
        }
      ],
      "source": [
        "print(chat.max_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2dGNE689ake4"
      },
      "outputs": [],
      "source": [
        "llm = OpenAI(model_name='text-davinci-003',temperature=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "ONQkBqfNarpq",
        "outputId": "dc5f9400-8bcc-434a-c833-447f8e411138"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'text-davinci-003'"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "llm.model_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ijcnZ8-auXn",
        "outputId": "9427f934-8ddb-4d8a-e1f4-7ca0fee3f840"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "256"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "llm.max_tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YuLgsfqvbKZK"
      },
      "source": [
        "# Prompt Template\n",
        "\n",
        "LangChain offers tools for crafting and utilizing prompt templates, which are pre-defined guidelines for generating prompts for language models, including instructions, few-shot examples, and context-specific questions suitable for various tasks. These templates aim to be model-agnostic, allowing for easy reuse across different language models. Generally, language models anticipate prompts to be either a string or a series of chat messages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ey4gVoEKayji"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import ChatPromptTemplate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MnLZC-jbgXd"
      },
      "source": [
        "Let's create a prompt template, notice the variables inside {} curly brackets are treated as input variables and can be overriden based on the user input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4hYAhnaDbcTe"
      },
      "outputs": [],
      "source": [
        "template = \"\"\"Generate a report highlighting the key findings from the {analysis_type} analysis. Here's a snippet of the analysis: \\\n",
        "```{analysis_snippet}```.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bfKpv3DgbuEk"
      },
      "outputs": [],
      "source": [
        "prompt_temp = ChatPromptTemplate.from_template(template)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JxMX0qjzb2jr",
        "outputId": "abbc6ebc-ac3f-465b-df64-d014b4df9448"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ChatPromptTemplate(input_variables=['analysis_snippet', 'analysis_type'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['analysis_snippet', 'analysis_type'], template=\"Generate a report highlighting the key findings from the {analysis_type} analysis. Here's a snippet of the analysis: ```{analysis_snippet}```.\\n\"))])\n"
          ]
        }
      ],
      "source": [
        "pprint(prompt_temp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPPRFSt7b4AW",
        "outputId": "48d869f8-df32-46e1-aab7-a3f29375b477"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['analysis_snippet', 'analysis_type']"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt_temp.input_variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ofH_HUUqcL9-",
        "outputId": "8361164a-544a-4ab0-d61d-745d6870907a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['analysis_snippet', 'analysis_type'], template=\"Generate a report highlighting the key findings from the {analysis_type} analysis. Here's a snippet of the analysis: ```{analysis_snippet}```.\\n\"))]"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt_temp.messages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uTs25xmXcQNW"
      },
      "outputs": [],
      "source": [
        "sample_analysis_type = \"user_engagement\"\n",
        "\n",
        "sample_analysis_snippet = \"\"\"\n",
        "Over the past quarter, the user engagement metrics have shown promising growth.\n",
        "The number of active users has increased by 15%, with a notable uptick in daily logins.\n",
        "This increase is largely attributed to the successful launch of our new mobile app, which has received positive feedback from users.\n",
        "Additionally, user interactions with key features, such as commenting and sharing, have risen by 20%.\n",
        "This signifies a higher level of user participation and social engagement within our platform.\n",
        "We've also observed longer average session durations, indicating that users are spending more time exploring the content we offer.\n",
        "The engagement rate, calculated by dividing interactions by active users, has experienced a steady increase of 10% over the past two months.\n",
        "This suggests that our efforts to improve user experience and introduce new features are resonating well with our audience.\n",
        "\n",
        "Overall, the data suggests that our focus on enhancing user engagement through product improvements and feature launches is yielding positive results. As we continue to refine our strategies and innovate, we can expect further growth in user interactions and overall engagement.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFlLDBUAccI_"
      },
      "source": [
        "Using format_messages function we can override the input variables used in the Prompt template"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mzU0Ss5VcaQP"
      },
      "outputs": [],
      "source": [
        "response_message = prompt_temp.format_messages(\n",
        "    analysis_type = sample_analysis_type,\n",
        "    analysis_snippet = sample_analysis_snippet\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g96hqbcncp_H",
        "outputId": "03665964-2c9e-42f7-aea1-0ad66a2a9495"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[HumanMessage(content=\"Generate a report highlighting the key findings from the user_engagement analysis. Here's a snippet of the analysis: ```\\nOver the past quarter, the user engagement metrics have shown promising growth.\\nThe number of active users has increased by 15%, with a notable uptick in daily logins.\\nThis increase is largely attributed to the successful launch of our new mobile app, which has received positive feedback from users.\\nAdditionally, user interactions with key features, such as commenting and sharing, have risen by 20%.\\nThis signifies a higher level of user participation and social engagement within our platform.\\nWe've also observed longer average session durations, indicating that users are spending more time exploring the content we offer.\\nThe engagement rate, calculated by dividing interactions by active users, has experienced a steady increase of 10% over the past two months.\\nThis suggests that our efforts to improve user experience and introduce new features are resonating well with our audience.\\n\\nOverall, the data suggests that our focus on enhancing user engagement through product improvements and feature launches is yielding positive results. As we continue to refine our strategies and innovate, we can expect further growth in user interactions and overall engagement.\\n```.\\n\")]"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response_message"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "id": "lbD35Kl6ctle",
        "outputId": "3b1e3b34-bc10-4d4e-ae1a-d14daf4b5c0a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"Generate a report highlighting the key findings from the user_engagement analysis. Here's a snippet of the analysis: ```\\nOver the past quarter, the user engagement metrics have shown promising growth.\\nThe number of active users has increased by 15%, with a notable uptick in daily logins.\\nThis increase is largely attributed to the successful launch of our new mobile app, which has received positive feedback from users.\\nAdditionally, user interactions with key features, such as commenting and sharing, have risen by 20%.\\nThis signifies a higher level of user participation and social engagement within our platform.\\nWe've also observed longer average session durations, indicating that users are spending more time exploring the content we offer.\\nThe engagement rate, calculated by dividing interactions by active users, has experienced a steady increase of 10% over the past two months.\\nThis suggests that our efforts to improve user experience and introduce new features are resonating well with our audience.\\n\\nOverall, the data suggests that our focus on enhancing user engagement through product improvements and feature launches is yielding positive results. As we continue to refine our strategies and innovate, we can expect further growth in user interactions and overall engagement.\\n```.\\n\""
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response_message[0].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kJLnu_D050BV"
      },
      "outputs": [],
      "source": [
        "report = chat(response_message) #chatopenai model-GPT3.5 turbo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aILVCnEb55uL"
      },
      "outputs": [],
      "source": [
        "report_llm = llm(response_message[0].content) #OpenAI -llms - Text davinci-003"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z0iTyanJ572q"
      },
      "outputs": [],
      "source": [
        "print(report.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7SIm6iO9575V"
      },
      "outputs": [],
      "source": [
        "print(report_llm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xy9UieIc6CYl"
      },
      "source": [
        "#Output in specific format and not string\n",
        "\n",
        "When developing an application, there may be a requirement for the response to adhere to a specific format, such as JSON or XML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GP9Z0pfq577x"
      },
      "outputs": [],
      "source": [
        "movie_review_template = \"\"\"\\\n",
        "For the following movie review, extract the following information:\n",
        "\n",
        "genre: Mentioned genres in the review. Extract and list them as a comma separated Python list.\n",
        "\n",
        "lead_chemistry: Describe the chemistry between the lead characters, if mentioned.\n",
        "\n",
        "plot_twists: Were any unexpected plot twists mentioned? Answer True if yes, False if not or unknown.\n",
        "\n",
        "runtime_feel: Did the reviewer mention their feelings about the movie's runtime? If yes, extract their sentiment about it.\n",
        "\n",
        "Format the output as JSON with the following keys:\n",
        "genre\n",
        "lead_chemistry\n",
        "plot_twists\n",
        "runtime_feel\n",
        "\n",
        "review_text: {review_text}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UsfM0Xp-57-N",
        "outputId": "2edc1c7b-1f43-4323-aad2-c248ddcfbdd7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['review_text'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['review_text'], template=\"For the following movie review, extract the following information:\\n\\ngenre: Mentioned genres in the review. Extract and list them as a comma separated Python list.\\n\\nlead_chemistry: Describe the chemistry between the lead characters, if mentioned.\\n\\nplot_twists: Were any unexpected plot twists mentioned? Answer True if yes, False if not or unknown.\\n\\nruntime_feel: Did the reviewer mention their feelings about the movie's runtime? If yes, extract their sentiment about it.\\n\\nFormat the output as JSON with the following keys:\\ngenre\\nlead_chemistry\\nplot_twists\\nruntime_feel\\n\\nreview_text: {review_text}\\n\"))])"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "movie_bot = ChatPromptTemplate.from_template(movie_review_template)\n",
        "movie_bot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxec3XkK6Yg9",
        "outputId": "edb3c2e8-66fc-4923-9714-afe8bfe1fe88"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['review_text']"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "movie_bot.input_variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fmWMpnG96bIF"
      },
      "outputs": [],
      "source": [
        "movie_review = \"\"\"\\\n",
        "This movie was an incredible cinematic experience. It offers a unique blend of genres:\\\n",
        "romance, drama, and thrilling action. The storyline is gripping, and the characters'\\\n",
        "emotional journey kept me engaged throughout. The visuals are stunning, especially\\\n",
        "during the breathtaking action sequences.\n",
        "\n",
        "The acting was exceptional, with the lead actors delivering performances that truly\\\n",
        "captured the essence of their roles. The chemistry between the main characters added\\\n",
        "depth to the romantic elements of the plot. The supporting cast also deserves praise,\\\n",
        "as they brought their characters to life convincingly.\n",
        "\n",
        "I was pleasantly surprised by the unexpected plot twists that kept me on the edge of\\\n",
        "my seat. The pacing was well-managed, allowing for a perfect balance between intense\\\n",
        "action and quieter, reflective moments.\n",
        "\n",
        "While the movie was a bit longer than usual, I found myself immersed in the story\\\n",
        "and didn't mind the extended runtime. It's a film that leaves a lasting impression,\\\n",
        "prompting viewers to reflect on its themes long after the credits roll.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LGGZhDzF6dQd"
      },
      "outputs": [],
      "source": [
        "delegate_review = movie_bot.format_messages(review_text = movie_review)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_jbIvUX6q37",
        "outputId": "e2ad7afc-a32d-42c9-fc2f-91c9c3da2e4f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[HumanMessage(content=\"For the following movie review, extract the following information:\\n\\ngenre: Mentioned genres in the review. Extract and list them as a comma separated Python list.\\n\\nlead_chemistry: Describe the chemistry between the lead characters, if mentioned.\\n\\nplot_twists: Were any unexpected plot twists mentioned? Answer True if yes, False if not or unknown.\\n\\nruntime_feel: Did the reviewer mention their feelings about the movie's runtime? If yes, extract their sentiment about it.\\n\\nFormat the output as JSON with the following keys:\\ngenre\\nlead_chemistry\\nplot_twists\\nruntime_feel\\n\\nreview_text: This movie was an incredible cinematic experience. It offers a unique blend of genres:romance, drama, and thrilling action. The storyline is gripping, and the characters'emotional journey kept me engaged throughout. The visuals are stunning, especiallyduring the breathtaking action sequences.\\n\\nThe acting was exceptional, with the lead actors delivering performances that trulycaptured the essence of their roles. The chemistry between the main characters addeddepth to the romantic elements of the plot. The supporting cast also deserves praise,as they brought their characters to life convincingly.\\n\\nI was pleasantly surprised by the unexpected plot twists that kept me on the edge ofmy seat. The pacing was well-managed, allowing for a perfect balance between intenseaction and quieter, reflective moments.\\n\\nWhile the movie was a bit longer than usual, I found myself immersed in the storyand didn't mind the extended runtime. It's a film that leaves a lasting impression,prompting viewers to reflect on its themes long after the credits roll.\\n\\n\")]"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "delegate_review"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BIlmhBgg6s3q"
      },
      "outputs": [],
      "source": [
        "get_movie_details = chat(delegate_review)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-ZlJZ5K8jH_"
      },
      "source": [
        "As you can see the output is in the json format but the data type is still string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jxiE3wD160sm"
      },
      "outputs": [],
      "source": [
        "print(get_movie_details.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tf51k6Vh91ZR"
      },
      "outputs": [],
      "source": [
        "get_movie_details.get(\"genre\")  # This will resutlt into error which can be solved using Output Parser"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TS0WhQuK7GlW"
      },
      "source": [
        "# Output Parser\n",
        "Language models output text. But many times you may want to get more structured information than just text back. This is where output parsers come in.\n",
        "\n",
        "Output parsers are classes that help structure language model responses. There are two main methods an output parser must implement:\n",
        "\n",
        "*   \"Get format instructions\": A method which returns a string containing instructions for how the output of a language model should be formatted.\n",
        "*   \"Parse\": A method which takes in a string (assumed to be the response from a language model) and parses it into some structure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dPqsOGb360zB"
      },
      "outputs": [],
      "source": [
        "from langchain.output_parsers import ResponseSchema\n",
        "from langchain.output_parsers import StructuredOutputParser"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lh8MHeGb7YRM"
      },
      "source": [
        "StructuredOutputParser output parser can be used when you want to return multiple fields. While the Pydantic/JSON parser is more powerful, we initially experimented with data structures having text fields only.\n",
        "\n",
        "To create such multiple data structures we use ResponseSchema"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8CgJUmdD7TH6"
      },
      "outputs": [],
      "source": [
        "genre_schema = ResponseSchema(name = \"genre\",\n",
        "description = \"Mentioned genres in the review. \\\n",
        "Extract and list them as comma separated Python list.\")\n",
        "\n",
        "lead_chemistry_schema = ResponseSchema(name=\"lead_chemistry\",\n",
        "description=\"Describe the chemistry between \\\n",
        "the lead characters, if mentioned.\")\n",
        "\n",
        "plot_twists_schema = ResponseSchema(name=\"plot_twists\",\n",
        "description=\"Were any unexpected plot twists mentioned? \\\n",
        "Answer True if yes, False if not or unknown.\")\n",
        "\n",
        "runtime_feel_schema = ResponseSchema(name=\"runtime_feel\",\n",
        "description=\"Did the reviewer mention their feelings about \\\n",
        "the movie's runtime? If yes, extract their sentiment about it.\")\n",
        "\n",
        "response_schemas = [genre_schema,\n",
        "lead_chemistry_schema,\n",
        "plot_twists_schema,\n",
        "runtime_feel_schema]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T0S5zuX_77fP"
      },
      "outputs": [],
      "source": [
        "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9KVkInKN8Mp9"
      },
      "outputs": [],
      "source": [
        "format_instructions = output_parser.get_format_instructions()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ly9UXK1j8SfP",
        "outputId": "8d7a8546-8cbf-4362-e5f9-f795997a851c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
            "\n",
            "```json\n",
            "{\n",
            "\t\"genre\": string  // Mentioned genres in the review. Extract and list them as comma separated Python list.\n",
            "\t\"lead_chemistry\": string  // Describe the chemistry between the lead characters, if mentioned.\n",
            "\t\"plot_twists\": string  // Were any unexpected plot twists mentioned? Answer True if yes, False if not or unknown.\n",
            "\t\"runtime_feel\": string  // Did the reviewer mention their feelings about the movie's runtime? If yes, extract their sentiment about it.\n",
            "}\n",
            "```\n"
          ]
        }
      ],
      "source": [
        "print(format_instructions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4z03HddP8per"
      },
      "source": [
        "Note: Use this format_instructions in your prompt template to get the response in JSON"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k31zJwAJ8VnK"
      },
      "outputs": [],
      "source": [
        "movie_review_template = \"\"\"\\\n",
        "For the following movie review, extract the following information:\n",
        "\n",
        "genre: Mentioned genres in the review. Extract and list them as a comma separated Python list.\n",
        "\n",
        "lead_chemistry: Describe the chemistry between the lead characters, if mentioned.\n",
        "\n",
        "plot_twists: Were any unexpected plot twists mentioned? Answer True if yes, False if not or unknown.\n",
        "\n",
        "runtime_feel: Did the reviewer mention their feelings about the movie's runtime? If yes, extract their sentiment about it.\n",
        "\n",
        "Format the output as JSON with the following keys:\n",
        "genre\n",
        "lead_chemistry\n",
        "plot_twists\n",
        "runtime_feel\n",
        "\n",
        "review_text: {review_text}\n",
        "\n",
        "{format_instructions}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lQqt0VVW8t6O"
      },
      "outputs": [],
      "source": [
        "prompt = ChatPromptTemplate.from_template(template=movie_review_template)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x2KzLR-C9ZrW"
      },
      "outputs": [],
      "source": [
        "user_review = prompt.format_messages(\n",
        "review_text=movie_review,\n",
        "format_instructions=format_instructions\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Is76kla89g9F"
      },
      "outputs": [],
      "source": [
        "response = chat(user_review)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Q0qkILx9kO7"
      },
      "outputs": [],
      "source": [
        "print(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cunLWVn59kRg"
      },
      "outputs": [],
      "source": [
        "final_ans = output_parser.parse(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A3us2s0x9nkz"
      },
      "outputs": [],
      "source": [
        "final_ans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IfEu1_vS9nnx"
      },
      "outputs": [],
      "source": [
        "final_ans.get(\"genre\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2QbbC6q96VG"
      },
      "source": [
        "# Chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uLg989zu951d"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import LLMChain\n",
        "from langchain.chains import SequentialChain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NUbqcNL49kUJ"
      },
      "outputs": [],
      "source": [
        "movie_review_template = \"\"\"\\\n",
        "For the following movie review, extract the following information:\n",
        "\n",
        "genre: Mentioned genres in the review. Extract and list them as a comma separated Python list.\n",
        "\n",
        "lead_chemistry: Describe the chemistry between the lead characters, if mentioned.\n",
        "\n",
        "plot_twists: Were any unexpected plot twists mentioned? Answer True if yes, False if not or unknown.\n",
        "\n",
        "runtime_feel: Did the reviewer mention their feelings about the movie's runtime? If yes, extract their sentiment about it.\n",
        "\n",
        "Format the output as JSON with the following keys:\n",
        "genre\n",
        "lead_chemistry\n",
        "plot_twists\n",
        "runtime_feel\n",
        "\n",
        "review_text: {review_text}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4CVfZgWJ-VtZ"
      },
      "outputs": [],
      "source": [
        "user_prompt = ChatPromptTemplate.from_template(movie_review_template)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b_W7vjhQ-WeW"
      },
      "outputs": [],
      "source": [
        "chat = ChatOpenAI(temperature=0.0) #ChatOPENAI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKVNlQ7LrRFl"
      },
      "source": [
        "# LLM Chain\n",
        "\n",
        "An LLMChain is a simple chain that adds some functionality around language models. It is used widely throughout LangChain, including in other chains and agents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D5184PzhsGg9"
      },
      "outputs": [],
      "source": [
        "chain = LLMChain(llm=chat,prompt=user_prompt,verbose=True) # by default - Verbose=False\n",
        "review_res = chain.run(movie_review)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "06LyqxYxwQ8L"
      },
      "outputs": [],
      "source": [
        "print(review_res)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dq2Nbs0JwTVI"
      },
      "source": [
        "## Sequential Chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uOjXcQTpwVDC"
      },
      "outputs": [],
      "source": [
        "chain_one = LLMChain(llm=chat,prompt=user_prompt,output_key = \"json_answer\") #outputkey can be any name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XW8Gu5ixwYh7"
      },
      "outputs": [],
      "source": [
        "summary_review = \"Please summarize the following review in 1 liner: {review_text}\"\n",
        "second_prompt_template = ChatPromptTemplate.from_template(summary_review)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZjtyvh1wfgD"
      },
      "outputs": [],
      "source": [
        "chain_two = LLMChain(llm =chat,prompt=second_prompt_template,output_key = \"summary\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qbn905_NwiM_"
      },
      "outputs": [],
      "source": [
        "seq_chain = SequentialChain(\n",
        "chains=[chain_one, chain_two],\n",
        "input_variables=[\"review_text\"],\n",
        "output_variables=[\"json_answer\", \"summary\"],\n",
        "verbose=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UMhQrtu3wlmg"
      },
      "outputs": [],
      "source": [
        "seq_response = seq_chain(movie_review)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B2jYsHOmwlpO"
      },
      "outputs": [],
      "source": [
        "seq_response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Rcmv9-1wqz_"
      },
      "source": [
        "# Memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c8Vbx3eKwluC"
      },
      "outputs": [],
      "source": [
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.chains import ConversationChain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CadKX4IMwxMB"
      },
      "outputs": [],
      "source": [
        "temp1 = ChatPromptTemplate.from_template(\"Hi, my name is {name}, I work at AI Planet\")\n",
        "temp1 = temp1.format_messages(name=\"Tarun Jain\")\n",
        "res = chat(temp1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MmdP1t1_wxT4"
      },
      "outputs": [],
      "source": [
        "res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qt0BgK5cwxZk"
      },
      "outputs": [],
      "source": [
        "temp2 = ChatPromptTemplate.from_template(\"As you know I work at {startup}. What is my name?\")\n",
        "temp2 = temp2.format_messages(startup=\"AI Planet\")\n",
        "res2 = chat(temp2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qnK2slpcxFvg"
      },
      "outputs": [],
      "source": [
        "res"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCa9jY4bxEse"
      },
      "source": [
        "Most LLM applications have a conversational interface. An essential component of a conversation is being able to refer to information introduced earlier in the conversation. At bare minimum, a conversational system should be able to access some window of past messages directly. A more complex system will need to have a world model that it is constantly updating, which allows it to do things like maintain information about entities and their relationships."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fbSffKLWxL1u"
      },
      "outputs": [],
      "source": [
        "memory = ConversationBufferMemory()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GfDJFNSjxN0H"
      },
      "outputs": [],
      "source": [
        "conversation = ConversationChain(\n",
        "llm=chat,\n",
        "memory = memory,\n",
        "verbose=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pxpDbL4IxN3J"
      },
      "outputs": [],
      "source": [
        "conversation.predict(input=\"Hi, my name is Tarun Jain, I work at AI Planet\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kIM8BaU0xN6K"
      },
      "outputs": [],
      "source": [
        "conversation.predict(input=\"At AI Planet I work as a DevRel & Community Manager\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nwd4vCgxxerh"
      },
      "outputs": [],
      "source": [
        "conversation.predict(input=\"What is my name?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7wEkyPZRxeuQ"
      },
      "outputs": [],
      "source": [
        "print(memory.buffer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDwRboOexlbA"
      },
      "source": [
        "# Agents\n",
        "\n",
        "Some applications will require not just a predetermined chain of calls to LLMs/other tools, but potentially an unknown chain that depends on the user's input. In these types of chains, there is a agent which has access to a suite of tools. Depending on the user input, the agent can then decide which, if any, of these tools to call."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5WK2QVOxew1",
        "outputId": "b4fd06d3-59fd-4b4a-9012-ae6453d513ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting duckduckgo-search\n",
            "  Downloading duckduckgo_search-6.2.1-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: click>=8.1.7 in /usr/local/lib/python3.10/dist-packages (from duckduckgo-search) (8.1.7)\n",
            "Collecting pyreqwest-impersonate>=0.5.0 (from duckduckgo-search)\n",
            "  Downloading pyreqwest_impersonate-0.5.1-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyreqwest-impersonate, duckduckgo-search\n",
            "Successfully installed duckduckgo-search-6.2.1 pyreqwest-impersonate-0.5.1\n"
          ]
        }
      ],
      "source": [
        "!pip install duckduckgo-search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M5tNLZHkxezr"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import Tool\n",
        "from langchain.agents import AgentType\n",
        "from langchain.utilities import DuckDuckGoSearchAPIWrapper\n",
        "from langchain.agents import initialize_agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tNtj15Jtxe2L"
      },
      "outputs": [],
      "source": [
        "search = DuckDuckGoSearchAPIWrapper()\n",
        "tools = [\n",
        "Tool(\n",
        "name = \"Search Engine\",\n",
        "func=search.run,\n",
        "description=\"To explore the world of internet\"\n",
        "),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_mOINB3x5SD"
      },
      "outputs": [],
      "source": [
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "llm = ChatOpenAI(openai_api_key=openai_key, temperature=0.0)\n",
        "agent_chain = initialize_agent(tools, llm, agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION, verbose=True, memory=memory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4BJD40iMx5U9"
      },
      "outputs": [],
      "source": [
        "agent_chain.run(input=\"Where is Bangalore located?\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
