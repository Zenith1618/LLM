{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOoIl2rdYXZFgQ+hHN3Xzuc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zenith1618/LLM/blob/main/Intro_Notebook_to_LlamaIndex_and_RAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installing Libraries and Setting up Env"
      ],
      "metadata": {
        "id": "95_HwUoP9x3q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTSKoc0Y4Pdl",
        "outputId": "341f259f-3dd9-4bb8-99bd-65f506ec7d32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: llama-index-llms-azure-openai in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
            "Requirement already satisfied: azure-identity<2.0.0,>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-llms-azure-openai) (1.17.1)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama-index-llms-azure-openai) (0.27.0)\n",
            "Requirement already satisfied: llama-index-core<0.12.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-llms-azure-openai) (0.11.1)\n",
            "Requirement already satisfied: llama-index-llms-openai<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-llms-azure-openai) (0.2.0)\n",
            "Requirement already satisfied: azure-core>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai) (1.30.2)\n",
            "Requirement already satisfied: cryptography>=2.5 in /usr/local/lib/python3.10/dist-packages (from azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai) (43.0.0)\n",
            "Requirement already satisfied: msal>=1.24.0 in /usr/local/lib/python3.10/dist-packages (from azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai) (1.30.0)\n",
            "Requirement already satisfied: msal-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai) (1.2.0)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai) (4.12.2)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-azure-openai) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-azure-openai) (2.0.32)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-azure-openai) (3.10.5)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-azure-openai) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-azure-openai) (1.2.14)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-azure-openai) (1.0.8)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-azure-openai) (2024.6.1)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-azure-openai) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-azure-openai) (3.3)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-azure-openai) (3.9.1)\n",
            "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-azure-openai) (1.26.4)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-azure-openai) (9.4.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-azure-openai) (2.8.2)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-azure-openai) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-azure-openai) (8.5.0)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-azure-openai) (0.7.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-azure-openai) (4.66.5)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-azure-openai) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-azure-openai) (1.16.0)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.40.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-llms-openai<0.3.0,>=0.2.0->llama-index-llms-azure-openai) (1.42.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-llms-azure-openai) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-llms-azure-openai) (2024.7.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-llms-azure-openai) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-llms-azure-openai) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-llms-azure-openai) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama-index-llms-azure-openai) (0.14.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-azure-openai) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-azure-openai) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-azure-openai) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-azure-openai) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-azure-openai) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-azure-openai) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-azure-openai) (4.0.3)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from azure-core>=1.23.0->azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai) (1.16.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=2.5->azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai) (1.17.0)\n",
            "Requirement already satisfied: PyJWT<3,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from PyJWT[crypto]<3,>=1.0.0->msal>=1.24.0->azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai) (2.9.0)\n",
            "Requirement already satisfied: portalocker<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from msal-extensions>=0.3.0->azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai) (2.10.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-azure-openai) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-azure-openai) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-azure-openai) (2024.5.15)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.40.0->llama-index-llms-openai<0.3.0,>=0.2.0->llama-index-llms-azure-openai) (1.7.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->llama-index-llms-openai<0.3.0,>=0.2.0->llama-index-llms-azure-openai) (0.5.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->llama-index-llms-azure-openai) (1.2.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.0.0->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-azure-openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.0.0->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-azure-openai) (2.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-azure-openai) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-azure-openai) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-azure-openai) (3.0.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-azure-openai) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-azure-openai) (3.22.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=2.5->azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai) (2.22)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-azure-openai) (24.1)\n",
            "Collecting llama-index-embeddings-azure-openai\n",
            "  Downloading llama_index_embeddings_azure_openai-0.2.3-py3-none-any.whl.metadata (746 bytes)\n",
            "Requirement already satisfied: llama-index-core<0.12.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-embeddings-azure-openai) (0.11.1)\n",
            "Requirement already satisfied: llama-index-embeddings-openai<0.3.0,>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-embeddings-azure-openai) (0.2.3)\n",
            "Requirement already satisfied: llama-index-llms-azure-openai<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-embeddings-azure-openai) (0.2.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-azure-openai) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-azure-openai) (2.0.32)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-azure-openai) (3.10.5)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-azure-openai) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-azure-openai) (1.2.14)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-azure-openai) (1.0.8)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-azure-openai) (2024.6.1)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-azure-openai) (0.27.0)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-azure-openai) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-azure-openai) (3.3)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-azure-openai) (3.9.1)\n",
            "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-azure-openai) (1.26.4)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-azure-openai) (9.4.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-azure-openai) (2.8.2)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-azure-openai) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-azure-openai) (8.5.0)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-azure-openai) (0.7.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-azure-openai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-azure-openai) (4.12.2)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-azure-openai) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-azure-openai) (1.16.0)\n",
            "Requirement already satisfied: openai>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-embeddings-openai<0.3.0,>=0.2.3->llama-index-embeddings-azure-openai) (1.42.0)\n",
            "Requirement already satisfied: azure-identity<2.0.0,>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-llms-azure-openai<0.3.0,>=0.2.0->llama-index-embeddings-azure-openai) (1.17.1)\n",
            "Requirement already satisfied: llama-index-llms-openai<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-llms-azure-openai<0.3.0,>=0.2.0->llama-index-embeddings-azure-openai) (0.2.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-azure-openai) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-azure-openai) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-azure-openai) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-azure-openai) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-azure-openai) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-azure-openai) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-azure-openai) (4.0.3)\n",
            "Requirement already satisfied: azure-core>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai<0.3.0,>=0.2.0->llama-index-embeddings-azure-openai) (1.30.2)\n",
            "Requirement already satisfied: cryptography>=2.5 in /usr/local/lib/python3.10/dist-packages (from azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai<0.3.0,>=0.2.0->llama-index-embeddings-azure-openai) (43.0.0)\n",
            "Requirement already satisfied: msal>=1.24.0 in /usr/local/lib/python3.10/dist-packages (from azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai<0.3.0,>=0.2.0->llama-index-embeddings-azure-openai) (1.30.0)\n",
            "Requirement already satisfied: msal-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai<0.3.0,>=0.2.0->llama-index-embeddings-azure-openai) (1.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-azure-openai) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-azure-openai) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-azure-openai) (2024.5.15)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->llama-index-embeddings-openai<0.3.0,>=0.2.3->llama-index-embeddings-azure-openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.1.0->llama-index-embeddings-openai<0.3.0,>=0.2.3->llama-index-embeddings-azure-openai) (1.7.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->llama-index-embeddings-openai<0.3.0,>=0.2.3->llama-index-embeddings-azure-openai) (0.5.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->llama-index-embeddings-openai<0.3.0,>=0.2.3->llama-index-embeddings-azure-openai) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-azure-openai) (2024.7.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-azure-openai) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-azure-openai) (3.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-azure-openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.0.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-azure-openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.0.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-azure-openai) (2.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-azure-openai) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-azure-openai) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-azure-openai) (3.0.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-azure-openai) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-azure-openai) (3.22.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1.1.0->llama-index-embeddings-openai<0.3.0,>=0.2.3->llama-index-embeddings-azure-openai) (1.2.2)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from azure-core>=1.23.0->azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai<0.3.0,>=0.2.0->llama-index-embeddings-azure-openai) (1.16.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=2.5->azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai<0.3.0,>=0.2.0->llama-index-embeddings-azure-openai) (1.17.0)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-azure-openai) (24.1)\n",
            "Requirement already satisfied: PyJWT<3,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from PyJWT[crypto]<3,>=1.0.0->msal>=1.24.0->azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai<0.3.0,>=0.2.0->llama-index-embeddings-azure-openai) (2.9.0)\n",
            "Requirement already satisfied: portalocker<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from msal-extensions>=0.3.0->azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai<0.3.0,>=0.2.0->llama-index-embeddings-azure-openai) (2.10.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=2.5->azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai<0.3.0,>=0.2.0->llama-index-embeddings-azure-openai) (2.22)\n",
            "Downloading llama_index_embeddings_azure_openai-0.2.3-py3-none-any.whl (3.3 kB)\n",
            "Installing collected packages: llama-index-embeddings-azure-openai\n",
            "Successfully installed llama-index-embeddings-azure-openai-0.2.3\n",
            "Requirement already satisfied: llama-index in /usr/local/lib/python3.10/dist-packages (0.11.1)\n",
            "Requirement already satisfied: llama-index-agent-openai<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.3.0)\n",
            "Requirement already satisfied: llama-index-cli<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.3.0)\n",
            "Requirement already satisfied: llama-index-core<0.12.0,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.11.1)\n",
            "Requirement already satisfied: llama-index-embeddings-openai<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.2.3)\n",
            "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.3.0)\n",
            "Requirement already satisfied: llama-index-legacy<0.10.0,>=0.9.48 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.9.48.post3)\n",
            "Requirement already satisfied: llama-index-llms-openai<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.2.0)\n",
            "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.2.0)\n",
            "Requirement already satisfied: llama-index-program-openai<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.2.0)\n",
            "Requirement already satisfied: llama-index-question-gen-openai<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.2.0)\n",
            "Requirement already satisfied: llama-index-readers-file<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.2.0)\n",
            "Requirement already satisfied: llama-index-readers-llama-parse>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.2.0)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index) (3.9.1)\n",
            "Requirement already satisfied: openai>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-agent-openai<0.4.0,>=0.3.0->llama-index) (1.42.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.1->llama-index) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.1->llama-index) (2.0.32)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.1->llama-index) (3.10.5)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.1->llama-index) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.1->llama-index) (1.2.14)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.1->llama-index) (1.0.8)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.1->llama-index) (2024.6.1)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.1->llama-index) (0.27.0)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.1->llama-index) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.1->llama-index) (3.3)\n",
            "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.1->llama-index) (1.26.4)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.1->llama-index) (9.4.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.1->llama-index) (2.8.2)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.1->llama-index) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.1->llama-index) (8.5.0)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.1->llama-index) (0.7.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.1->llama-index) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.1->llama-index) (4.12.2)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.1->llama-index) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.1->llama-index) (1.16.0)\n",
            "Requirement already satisfied: llama-cloud>=0.0.11 in /usr/local/lib/python3.10/dist-packages (from llama-index-indices-managed-llama-cloud>=0.3.0->llama-index) (0.0.15)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-legacy<0.10.0,>=0.9.48->llama-index) (2.1.4)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file<0.3.0,>=0.2.0->llama-index) (4.12.3)\n",
            "Requirement already satisfied: pypdf<5.0.0,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file<0.3.0,>=0.2.0->llama-index) (4.3.1)\n",
            "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file<0.3.0,>=0.2.0->llama-index) (0.0.26)\n",
            "Requirement already satisfied: llama-parse>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-llama-parse>=0.2.0->llama-index) (0.5.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index) (2024.5.15)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.1->llama-index) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.1->llama-index) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.1->llama-index) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.1->llama-index) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.1->llama-index) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.1->llama-index) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.1->llama-index) (4.0.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.3.0,>=0.2.0->llama-index) (2.6)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.12.0,>=0.11.1->llama-index) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.12.0,>=0.11.1->llama-index) (2024.7.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.12.0,>=0.11.1->llama-index) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.12.0,>=0.11.1->llama-index) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.12.0,>=0.11.1->llama-index) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.12.0,>=0.11.1->llama-index) (0.14.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.4.0,>=0.3.0->llama-index) (1.7.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.4.0,>=0.3.0->llama-index) (0.5.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.0.0->llama-index-core<0.12.0,>=0.11.1->llama-index) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.0.0->llama-index-core<0.12.0,>=0.11.1->llama-index) (2.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.1->llama-index) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.1->llama-index) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.1->llama-index) (3.0.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.1->llama-index) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index-core<0.12.0,>=0.11.1->llama-index) (3.22.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index) (2024.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->llama-index-core<0.12.0,>=0.11.1->llama-index) (1.2.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.12.0,>=0.11.1->llama-index) (24.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "%pip install llama-index-llms-azure-openai\n",
        "%pip install llama-index-embeddings-azure-openai\n",
        "!pip install llama-index"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"6359488b89ab45d2ac5fc78aeee9a4b8\"\n",
        "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"https://openaillm69.openai.azure.com/\"\n",
        "os.environ[\"OPENAI_API_VERSION\"] = \"2024-05-01-preview\""
      ],
      "metadata": {
        "id": "owkR5KwY5UkI"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
        "azure_endpoint = os.environ.get(\"AZURE_OPENAI_ENDPOINT\")\n",
        "api_version = os.environ.get(\"OPENAI_API_VERSION\")"
      ],
      "metadata": {
        "id": "UOfSHtOM4LTS"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.embeddings.azure_openai import AzureOpenAIEmbedding\n",
        "\n",
        "embed_model = AzureOpenAIEmbedding(\n",
        "    model=\"text-embedding-ada-002\",\n",
        "    deployment_name=\"embedModel\",\n",
        "    api_key=api_key,\n",
        "    azure_endpoint=azure_endpoint,\n",
        "    api_version=api_version,\n",
        ")"
      ],
      "metadata": {
        "id": "P0iqYHO3Glu1"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import Settings\n",
        "\n",
        "Settings.llm = llm\n",
        "Settings.embed_model = embed_model  #used to build index"
      ],
      "metadata": {
        "id": "3uEWrgIE5H4e"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiments with LLM"
      ],
      "metadata": {
        "id": "jBDSZeQL96Sp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.llms.azure_openai import AzureOpenAI\n",
        "from llama_index.core.llms import ChatMessage\n",
        "\n",
        "llm = AzureOpenAI(engine=\"ragModel\")\n",
        "\n",
        "message = [\n",
        "    ChatMessage(role=\"system\", content = \"You are an AI assistant to user.\"),\n",
        "    ChatMessage(role=\"user\", content = \"What is the revenue of uber in 2023?\")\n",
        "]\n",
        "\n",
        "response = llm.chat(message)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lgE0y-nb7hp0",
        "outputId": "6ac7a33f-827e-4fa4-8116-84cc69e58eca"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "assistant: I'm sorry, but as an AI assistant, I cannot predict the future with certainty. However, according to Uber's financial reports, their revenue has been steadily increasing over the years. It is possible that their revenue will continue to grow in 2023, but it is impossible to provide an exact figure.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Connector\n",
        "\n",
        "A Data connector in LlamaIndex is a functional component that facilitates the conversion of data from various sources like PDF's, Youtube Videos, Audio Files, webpages, SQL Databases, docx etc into a Document format, making it ready for ingestion by LlamaIndex"
      ],
      "metadata": {
        "id": "rcmkVTtV_yE1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "from llama_index.core import download_loader\n",
        "\n",
        "PDFReader = download_loader(\"PDFReader\")\n",
        "loader = PDFReader()\n",
        "documents = loader.load_data(file=Path('uber_2023.pdf'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPGiPKZR94M4",
        "outputId": "1038f340-f67f-4e7e-d8c7-4059441e66fa"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-388cc9df281e>:4: DeprecationWarning: Call to deprecated function (or staticmethod) download_loader. (`download_loader()` is deprecated. Please install tool using pip install directly instead.)\n",
            "  PDFReader = download_loader(\"PDFReader\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "documents[8]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NEZrj-JCBOwR",
        "outputId": "6e04e795-0555-49d5-9e61-5537e5ccee88"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(id_='c69daed1-bf60-4614-aab8-b8e247e9c769', embedding=None, metadata={'page_label': 'i', 'file_name': 'uber_2023.pdf'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='Together, these elements power movement from point A to point B.\\nMassive Network Our massive, efficient, and intelligent network consists of tens of millions of Drivers , consumers, \\nMerchants , Shippers  and Carriers , as well as underlying data, technology, and shared infrastructure. \\nOur network becomes smarter with every trip. In more than 10,000  cities around the world (as of \\nDecember 31, 2023), our network powers movement at the touch of a button for millions, and we hope \\neventually billions, of people.\\nLeading Technology We have built proprietary marketplace, routing, and payments technologies. Marketplace technologies \\nare the core of our deep technology advantage and include demand prediction, matching and \\ndispatching, and pricing technologies. Our technologies make it extremely efficient to launch new \\nbusinesses and operationalize existing ones.\\nOperational Excellence Our regional on-the-ground operations teams use their extensive market-specific knowledge to rapidly \\nlaunch and scale products in cities, support Drivers , consumers, Merchants , Shippers , and Carriers , and \\nbuild and enhance relationships with cities and regulators.\\nProduct Expertise Our products are built with the expertise that allows us to set the standard for powering movement on-\\ndemand, provide platform users with a contextual, intuitive interface, continually evolve features and \\nfunctionality, and deliver safety and trust.\\nWe intend to continue to invest in new platform offerings that we believe will further strengthen our platform and existing \\nofferings.\\nWe believe that all of these synergies serve the customer experience, enabling us to attract new platform users and to deepen \\nengagement with existing platform users. Both of these dynamics grow our network scale and liquidity, which further increases the \\nvalue of our platform-to-platform users. For example, Delivery  attracts new consumers to our network—for the three months ended \\nDecember 31, 2023 , over 60% of first-time Delivery  consumers were new to our platform. Additionally, for the three months ended \\nDecember 31, 2023 , consumers who used both Mobility  and Delivery  generated 10.5 Trips per month on average, compared to 5.0 \\nTrips per month on average for consumers who used a single offering in cities where both Mobility  and Delivery  were offered . We \\nbelieve that these trends will improve as we further leverage the power of our platform.\\nWith our platform, we are making it even easier for our consumers to unlock convenience. In 2020, we rolled out our “Super \\nApp” view on iOS and Android, which combines our multiple offerings into a single app and is designed to remove friction for our \\nconsumers. During November 2021, we launched Uber One in the United States as our single cross-platform membership program \\nthat brings together the best of Uber. Uber One members have access to discounts, special pricing, priority service, and exclusive \\nperks across our rides, delivery and grocery offerings. Since then, we have expanded Uber One to  approximately 25 countries . Our \\nEats Pass membership program continues to remain available in select cities as a subscription offering. Our membership programs are \\ndesigned to make utilizing our suite of products a seamless and rewarding experience for our consumers. We exite d 2023  with  19 \\nmillion  members for our Uber One, Eats Pass and Rides Pass membership programs. \\nWe are also utilizing our data and scale to offer marketplace-centric advertising to connect merchants and brands with our \\nplatform network and unlocking cross-platform advertising formats. During October 2022, we officially launched Uber’s advertising \\ndivision and introduced Uber Journey Ads, an engaging way for brands to connect with consumers throughout the entire ride process. \\nWe now offer a model that enables brands to partner with Uber on a variety of advertising options on the Uber and Uber Eats apps, \\nand beyond, while connecting with consumers in brand-safe and captivating ways. We also provide comprehensive reporting and \\nanalysis, which helps brands fine-tune their understanding of consumers and create more impactful campaigns as they connect with \\nconsumers at relevant points throughout their journeys and transactions. During the fourth quarter of 2023 , active advertising \\nmerchants exceeded 550,000 . We believe that our advertising further strengthens the power of our platform and will continue to do so \\nas we onboard more advertisers.\\nCompetitive Environment\\nWe compete on a global basis in highly fragmented markets. We face significant competition in each of the mobility and delivery \\nindustries globally and in the logistics industry in the United States and Canada from existing, well-established, and low-cost \\nalternatives, and in the future we expect to face competition from new market entrants given the low barriers to entry that characterize \\nthese industries. As we and our competitors introduce new products and offerings, and as existing products evolve, we expect to \\nbecome subject to additional competition. While we work to expand globally and introduce new products and offerings across a range \\nof industries, many of our competitors remain focused on a limited number of products or on a narrow geographic scope, allowing \\nthem to develop specialized expertise and employ resources in a more targeted manner than we do. The competition we face in each of \\nour offerings includes:\\n•Mobility . Our Mobility  offering competes with personal vehicle ownership and usage, which accounts for the majority of \\npassenger miles in the markets that we serve, and traditional transportation services, including taxicab companies and taxi-\\nhailing services, livery and other car services. In addition, public transportation can be a superior substitute to our Mobility  \\noffering and in many cases, offers a faster and lower-cost travel option in many cities. We also compete with other \\n5', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(documents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UoyakPO1Cgni",
        "outputId": "81e69c32-95e5-46e5-8557-a2d1075bf517"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "148"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Core Components of LlamaIndex\n",
        "\n",
        "1. Index: It's the \"library\" of your data- Stores your data.\n",
        "2. Retriever: It's the \"librarian\" that finds relevant data - Finds Data.\n",
        "3. Response Synthesizer: It's the \"storyteller\" that creates a response - Make responses.\n",
        "4. QueryEngine: It's the \"director\" that makes everything works together - Coordinates Everything"
      ],
      "metadata": {
        "id": "H3O5QofaCZCi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.node_parser import SimpleNodeParser\n",
        "from llama_index.core import VectorStoreIndex, Settings\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "#create parser and parse the document\n",
        "parser = SimpleNodeParser()\n",
        "nodes = parser.get_nodes_from_documents(documents)\n",
        "\n",
        "#build index\n",
        "index = VectorStoreIndex(nodes)\n",
        "\n",
        "#Construct Query Engine\n",
        "query_engine = index.as_query_engine()\n",
        "\n",
        "#Query the engine\n",
        "response = query_engine.query(\"What is the revenue of uber in 2023?\")\n",
        "\n",
        "#print the response\n",
        "display(HTML(f'<p style=\"font-size:20px\">{response.response}</p>'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "IALxaCEyEbNs",
        "outputId": "b0738f59-d5ef-4789-c7df-4a151e3b5c32"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<p style=\"font-size:20px\">The revenue of Uber in 2023 is $37,281 million.</p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adding one more document"
      ],
      "metadata": {
        "id": "DgaZ1KvW5s2z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import SimpleDirectoryReader\n",
        "\n",
        "reader = SimpleDirectoryReader(input_files=[\"paul_graham_essay.txt\"])\n",
        "documents = reader.load_data()"
      ],
      "metadata": {
        "id": "hI7lxFcoFYLm"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create new nodes\n",
        "new_nodes = parser.get_nodes_from_documents(documents)\n",
        "\n",
        "# Add nodes to existing index\n",
        "index.insert_nodes(new_nodes)\n",
        "\n",
        "#Construct Query Engine\n",
        "query_engine = index.as_query_engine()\n",
        "\n",
        "#Query the engine\n",
        "response = query_engine.query(\"Why did paul graham start YC?\")\n",
        "\n",
        "#print the response\n",
        "display(HTML(f'<p style=\"font-size:20px\">{response.response}</p>'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "dwR1-eVv66iR",
        "outputId": "6c704e8a-e5af-4937-9800-82b4600f49c5"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<p style=\"font-size:20px\">The context information does not provide a direct answer to why Paul Graham started YC. However, he mentions that he enjoyed working at YC because the problems of the startups that came to them were varied and engaging. He also mentions that he worked hard to make YC successful. Later on, he decided to hand over YC to someone else and pursue a different path, which was painting.</p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Query the engine\n",
        "response = query_engine.query(\"What did the author do growing up?\")\n",
        "\n",
        "#print the response\n",
        "display(HTML(f'<p style=\"font-size:20px\">{response.response}</p>'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "9CqjS7fk7Zjs",
        "outputId": "86f30586-a25c-4607-fcf1-7e0cb3982bf7"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<p style=\"font-size:20px\">The author worked on writing and programming outside of school before college. They wrote short stories and tried writing programs on an IBM 1401 using an early version of Fortran. With microcomputers, the author started programming more and wrote simple games, a program to predict how high their model rockets would fly, and a word processor that their father used to write at least one book.</p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defining Retriever and response synthesizer(Customizing)\n",
        "\n",
        "We can even customize nodes, llm parameter, embed model parameter etc"
      ],
      "metadata": {
        "id": "3cXk9Qar-Hv3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.retrievers import VectorIndexRetriever\n",
        "from llama_index.core import get_response_synthesizer\n",
        "from llama_index.core.query_engine import RetrieverQueryEngine\n",
        "\n",
        "# define retriever\n",
        "retriever = VectorIndexRetriever(\n",
        "    index=index,\n",
        "    similarity_top_k=3\n",
        ")\n",
        "\n",
        "# configure response synthesizer\n",
        "response_synthesizer = get_response_synthesizer(\n",
        "    response_mode=\"accumulate\"\n",
        ")\n",
        "\n",
        "# assemble query engine\n",
        "query_engine = RetrieverQueryEngine(\n",
        "    retriever=retriever,\n",
        "    response_synthesizer=response_synthesizer\n",
        ")\n",
        "\n",
        "#Query the engine\n",
        "response = query_engine.query(\"What information do you have about zomato investment?\")\n",
        "\n",
        "#print the response\n",
        "display(HTML(f'<p style=\"font-size:20px\">{response.response}</p>'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "id": "QYbvesL09_N1",
        "outputId": "453b539c-9b38-43ea-b6e2-632d39bf75d9"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<p style=\"font-size:20px\">Response 1: Zomato investment was previously held as preferred shares and was classified as non-marketable equity securities and accounted for under the measurement alternative on a non-recurring basis. However, upon completion of its IPO in India, the investment was converted to ordinary shares and was classified as a marketable equity security with a readily determinable fair value (Level 1). The company recognized an unrealized gain of $991 million on this investment in other income (expense), net in the consolidated statement of operations for the year ended December 31, 2021. Additionally, during the third quarter of 2022, the company completed the sale of $418 million of its entire stake in Zomato ordinary shares for net proceeds of $376 million and recognized an immaterial loss from this transaction in other income (expense), net in the consolidated statement of operations.\n",
              "---------------------\n",
              "Response 2: There is no information provided in the given context about any investment in Zomato. The context only mentions minority ownership positions in Didi, Grab, Lime, and Aurora, and the risks associated with those investments.\n",
              "---------------------\n",
              "Response 3: There is no information provided about Zomato investment in the given context.</p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Node Post Processor\n",
        "\n",
        "Once we retreive from the retriever, but now i want to filter the nodes i got on some criteria, like certain keywords or similarity score"
      ],
      "metadata": {
        "id": "VM4FtZkIApF7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.postprocessor import SimilarityPostprocessor\n",
        "\n",
        "# Filtering nodes with similarity score\n",
        "node_post_processor = SimilarityPostprocessor(similarity_cutoff=0.7)\n",
        "\n",
        "query_engine = index.as_query_engine(node_postprocessors = [node_post_processor])\n",
        "\n",
        "#Query the engine\n",
        "response = query_engine.query(\"What information do you have about zomato investment?\")\n",
        "\n",
        "#print the response\n",
        "display(HTML(f'<p style=\"font-size:20px\">{response.response}</p>'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "mZv_WBPd-1lW",
        "outputId": "4fb66375-eb3c-4ddb-9ed6-f5f75bf2df2a"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<p style=\"font-size:20px\">Zomato is a company in which the organization holds preferred shares that were previously classified as non-marketable equity securities and accounted for under the measurement alternative on a non-recurring basis. In July 2021, Zomato completed its IPO in India, and accordingly, the organization's Zomato investment was converted to ordinary shares upon the completion of the IPO and was classified as a marketable equity security with a readily determinable fair value (Level 1). During the year ended December 31, 2021, the organization recognized an unrealized gain of $991 million on this investment in other income (expense), net in its consolidated statement of operations. During the third quarter of 2022, the organization completed the sale of $418 million of its entire stake in Zomato ordinary shares for net proceeds of $376 million and recognized an immaterial loss from this transaction in other income (expense), net in its consolidated statement of operations.</p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Querying over Multiple indices\n",
        "\n"
      ],
      "metadata": {
        "id": "zp50pOxyHjjH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Router Query Engine\n",
        "\n",
        "Example we have 2 indices, vectorstore(specific context queries) and List index(Summarization), now router engine is used to decide which one to use"
      ],
      "metadata": {
        "id": "I5bV2OcTHrKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import SummaryIndex\n",
        "\n",
        "summary_index = SummaryIndex(new_nodes)\n",
        "vector_index = VectorStoreIndex(new_nodes)\n"
      ],
      "metadata": {
        "id": "PDweIEOjCBA_"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary_query_engine = summary_index.as_query_engine(\n",
        "    response_mode=\"tree_summarize\",\n",
        "    # use_async = True\n",
        ")\n",
        "vector_query_engine = vector_index.as_query_engine()"
      ],
      "metadata": {
        "id": "2DuWCAOvHrkw"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.tools import QueryEngineTool\n",
        "\n",
        "summary_tool = QueryEngineTool.from_defaults(\n",
        "    query_engine = summary_query_engine,\n",
        "    description = \"Useful for summarization question related to Paul Graham Essay\"\n",
        ")\n",
        "\n",
        "vector_tool = QueryEngineTool.from_defaults(\n",
        "    query_engine = vector_query_engine,\n",
        "    description = \"Useful for retrieving specific context from Paul Graham Essay\"\n",
        ")"
      ],
      "metadata": {
        "id": "evBEZMAlIqzm"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.query_engine import RouterQueryEngine\n",
        "from llama_index.core.selectors import LLMSingleSelector\n",
        "\n",
        "query_engine = RouterQueryEngine(\n",
        "    selector = LLMSingleSelector.from_defaults(),\n",
        "    query_engine_tools = [summary_tool, vector_tool]\n",
        ")"
      ],
      "metadata": {
        "id": "44c7Xa3_JSCZ"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Query the engine\n",
        "response = query_engine.query(\"What is the summary of the document?\")\n",
        "\n",
        "#print the response\n",
        "display(HTML(f'<p style=\"font-size:20px\">{response.response}</p>'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "VrliAxy2Jz1d",
        "outputId": "3f541f44-4c00-4a79-8c8d-9413ae06e447"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<p style=\"font-size:20px\">The document is a collection of essays by Paul Graham, covering various topics such as his experiences with computers, art, startups, and venture capital. The essays reflect on his personal experiences and offer insights into the development of Lisp programming language, the evolution of startups and venture capital, the importance of pursuing one's passions, and the value of being independent-minded. The essays also discuss Graham's experiences as an entrepreneur, investor, and writer, including his founding of Y Combinator, a startup accelerator, and his decision to step down from running it to pursue painting, writing essays, and working on Lisp programming language.</p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Query the engine\n",
        "response = query_engine.query(\"Why did paul graham start YC.\")\n",
        "\n",
        "#print the response\n",
        "display(HTML(f'<p style=\"font-size:20px\">{response.response}</p>'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "vK1ZHzHpJ3v0",
        "outputId": "9e50435d-1d44-41f0-c0c9-76515c354570"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<p style=\"font-size:20px\">Paul Graham started Y Combinator to help startups in their early stages by providing them with seed investments and support in setting up their companies. He wanted to do for startups everything that had been done for him when he was starting his own company. The program initially started as a summer program for undergrads to start their own startups instead of taking temporary jobs at tech companies, but eventually evolved into a seed investment firm that aimed to help startups with everything from funding to incorporation. The batch model, where a group of startups are funded all at once and given intensive support for three months, was discovered by accident but proved to be a successful way to scale startup funding and solve the problem of isolation faced by many founders.</p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Subquestion Query Engine\n",
        "\n",
        "Example: compare revenue growth of uber and lyft in 2023.<br>\n",
        "Here we will have 2 different document to get the revenue for both the company and we will need to combine the answer."
      ],
      "metadata": {
        "id": "hFLP_w7MKwkW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.query_engine import SubQuestionQueryEngine\n",
        "\n",
        "lyft_docs = SimpleDirectoryReader(input_files=[\"lyft_2023.pdf\"]).load_data()\n",
        "uber_docs = SimpleDirectoryReader(input_files=[\"uber_2023.pdf\"]).load_data()"
      ],
      "metadata": {
        "id": "pAdMpflDKoss"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Indices: If you dont want to play with nodes and directly create indices we can do that as well\n",
        "\n",
        "lyft_index = VectorStoreIndex.from_documents(lyft_docs)\n",
        "uber_index = VectorStoreIndex.from_documents(uber_docs)"
      ],
      "metadata": {
        "id": "ghcJN8SML5qp"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Basic QA"
      ],
      "metadata": {
        "id": "zPxHnKrnMI9S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lyft_engine = lyft_index.as_query_engine(similarity_top_k = 3)\n",
        "uber_engine = uber_index.as_query_engine(similarity_top_k = 3)"
      ],
      "metadata": {
        "id": "VOMeFVFNMETj"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = await uber_engine.aquery(\"What is the revenue of uber in 2023?\")\n",
        "display(HTML(f'<p style=\"font-size:20px\">{response.response}</p>'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "mNCsmeWsMg1u",
        "outputId": "e501a117-1eff-44af-858f-009cb3d3d96c"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<p style=\"font-size:20px\">The revenue of Uber in 2023 was $37.3 billion, which represents a 17% increase compared to the previous year.</p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = lyft_engine.query(\"What is the revenue of lyft in 2023?\")\n",
        "display(HTML(f'<p style=\"font-size:20px\">{response.response}</p>'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "3vAMHa9DMsZy",
        "outputId": "3f2a215b-bd56-454e-9604-cd9fa71de593"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<p style=\"font-size:20px\">Lyft's revenue in 2023 was $4,403,589 thousand.</p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
        "\n",
        "query_engine_tools = [\n",
        "    QueryEngineTool(\n",
        "        query_engine = lyft_engine,\n",
        "        metadata = ToolMetadata(name = \"lyft_10k\", description = \"Provides information about Lyft\")\n",
        "    ),\n",
        "    QueryEngineTool(\n",
        "        query_engine = uber_engine,\n",
        "        metadata = ToolMetadata(name = \"uber_10k\", description = \"Provides information about Uber\")\n",
        "    )\n",
        "]\n",
        "\n",
        "s_engine = SubQuestionQueryEngine.from_defaults(query_engine_tools=query_engine_tools, use_async=True,)"
      ],
      "metadata": {
        "id": "lvyMgvovMwXh"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = await s_engine.aquery('Compare the growth of revenue of uber and lyft from 2021 to 2023')\n",
        "display(HTML(f'<p style=\"font-size:20px\">{response.response}</p>'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "id": "V1OW0xCHNx7q",
        "outputId": "fa435e54-d1a1-4179-9de8-4f59bc04455b"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated 4 sub questions.\n",
            "\u001b[1;3;38;2;237;90;200m[uber_10k] Q: What is the revenue of Uber in 2021?\n",
            "\u001b[0m\u001b[1;3;38;2;90;149;237m[uber_10k] Q: What is the revenue of Uber in 2023?\n",
            "\u001b[0m\u001b[1;3;38;2;11;159;203m[lyft_10k] Q: What is the revenue of Lyft in 2021?\n",
            "\u001b[0m\u001b[1;3;38;2;155;135;227m[lyft_10k] Q: What is the revenue of Lyft in 2023?\n",
            "\u001b[0m\u001b[1;3;38;2;11;159;203m[lyft_10k] A: Lyft's revenue in 2021 was $3,208,323 thousand.\n",
            "\u001b[0m\u001b[1;3;38;2;90;149;237m[uber_10k] A: The revenue of Uber in 2023 was $37.3 billion, which represents a 17% increase compared to the previous year.\n",
            "\u001b[0m\u001b[1;3;38;2;237;90;200m[uber_10k] A: The revenue of Uber in 2021 was $17,455 million.\n",
            "\u001b[0m\u001b[1;3;38;2;155;135;227m[lyft_10k] A: Lyft's revenue in 2023 was $4,403,589 thousand.\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<p style=\"font-size:20px\">From 2021 to 2023, both Uber and Lyft experienced growth in revenue. Uber's revenue increased from $17,455 million to $37.3 billion, representing a significant increase of 17%. On the other hand, Lyft's revenue increased from $3,208,323 thousand to $4,403,589 thousand, which is also a growth in revenue. However, the percentage increase in Lyft's revenue is not provided in the given context.</p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The comparison between the document is done but internally we did some semantic search backend because each of these queries were posed to the respective query engine and the answer was combined"
      ],
      "metadata": {
        "id": "BOoQuYrvRCLr"
      }
    }
  ]
}